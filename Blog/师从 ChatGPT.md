---
title: 师从 ChatGPT
description: 这篇文章介绍了作者师从ChatGPT后对思维模型和元认知的学习和领悟。作者通过思考和阅读书籍等学习途径，理解到元认知对认知过程的重要性。文章详细解释了认知的过程和元认知的定义，并强调了自我监控和自我调节在元认知中的重要性。同时，作者提到了方法论对认知过程的指导作用，以及思维模型在复杂问题理解和决策中的应用。最后，作者分享了对AI技术（如ChatGPT）的认知和思考方式的改变，以及对元认知的进一步理解。
keywords:
  - 元认知
  - 方法论
  - 思维模型
  - ChatGPT
tags:
  - 成长/个人
  - 博客/原创
authors:
  - 仲平
date: 2024-04-17
---

我最近遇见的很多问题处理起来感觉效率太低，总认为是因为没有熟练掌握方法论的具体应用——思维模型，才导致效率不高。所以就想系统全面地学习一下常见的思维模型。可是却又无从下手，毕竟思维模型实在是太多了。遂去问了问 ChatGPT，但又感觉 ChatGPT 的答案总是没有灵魂，似是非是的回答让我头大。然后几乎每天都在带着这个问题思考，不过也是功夫不负有心人。最终串联起来许多在书中读到的内容，并且进一步领悟到了最核心的点在于——元认知。

我第一次学习了解到元认知是在《认知觉醒》中，当时只觉得这只是一种方法论。但是又回过头来再次复读，现在我说实话能理解作者想表达的意思，但是其文字对于我来说增加了理解成本。或者，当初的我只停留在感性认识，并且没有去实践，可我感觉这又很难去实践。就好像只有恶龙诞生了，人们才会锻造出屠龙宝刀。但如果一开始没有恶龙，那么它就是一把普普通通的剑。

如果想认识元认知，首先要理解认知是什么？认知是人们获得知识或应用知识的过程，认知的对象是外在的，具体的。认知是感性认识转换理性认识的过程，并尝试通过不断的实践总结、迭代优化，最终尝试达到知行合一的境界。

例如当你第一次尝试骑自行车，可能会在父母的帮助下保持平衡，并尝试踩踏板来前进。如果父母放开手，你可能会跌倒几次，并开始思考为什么会失去平衡，是否是因为速度太慢或转向太急？可能你也会观察其他小朋友如何骑车，并尝试调整自己的速度和转向方式，学习如何更好地保持平衡。

当你学会骑自行车后，可能就会有朋友来向你请教。你就会根据自己的经验，教导他们如何调整速度并保持平衡。在教导他人的过程中，你可能会发现自己之前没注意到的技巧或细节，从而进一步改善自己的骑行技术。

一开始，对自行车的两个轮如何保持平衡，如何运动。你会形成直观的感性印象。这一阶段的认识是具体的、零散的，只能把握事物的外部特征和表面现象。期间通过实践，进一步将感性材料加以整理、抽象，形成概念、判断和推理，从而揭示事物的内部联系、本质特征和规律性。这一阶段的认识是抽象的、系统的，能够深入到事物的本质。

认知过程是由感性认识开始，通过实践再收获理性认识，最后又回到实践中去的迭代过程。在这一过程中，实践活动会不断产生新的感性认识，并通过加工不断收获新的理性认知，并再应用于实践。认知在这一过程中不断被纠正和发展，从而使认知逐步深化，逐渐接近于客观事物的真实状态。

而元认知相较于认知，则是内在的，抽象的，是基于我们自身的认知活动，是关于自己认知过程的认知，是我们如何认知这个世界，并进一步抽象所来的事物。元认知就像学习骑自行车的过程一样，是一个持续反思和调整的过程。在这个过程中，我们不仅要关注行动的直接结果，还要持续监控和调整自己的认知策略和方法。

所以元认知关键涉及自我监控和自我调节两大能力。

自我监控是指在认知活动中对自己的理解、注意力、记忆等进行监督和评估。例如，当你阅读新的文章时，你可能会不时地停下来，回顾自己理解的内容，检查是否有误解的地方。这就是一种元认知监控的具体体现。

自我调节则是指在认知过程中根据自我监控的结果来调整自己的学习行为。如果你在阅读过程中发现某些概念理解得不够深入，可能就会选择重新阅读相关段落，或者寻找更多资源来加深理解。这种能力不仅有助于提高学习效率，也使得学习过程更加适应个人的需求。

如果在实践中发展元认知能力，首先需要培养对自己认知过程的意识。这可以通过日常的反思练习开始，比如每天结束时回顾一下自己的学习和工作，思考哪些方法有效？哪些需要改进？此外，可以尝试在做决策时有意识地思考自己的认知过程，评估自己的思维是否合逻辑？是否受到了情绪的影响？想必通过这些方法，你就可以开始慢慢地培养出对自己认知过程的敏感度，并逐渐提高元认知能力。高水平的元认知能力会让你在面对充满挑战性的情境时，能更加自如地调整策略，以达到最佳的认知和学习效果。

我认为如果能充分，理解，提高，运用元认知能力，那么认知的成长将不再是 1+1 的积累，而是指数级的倍增。这种能力就像是锻造了一把屠龙宝刀，使你能够更有效地面对生活和工作中的各种挑战。

而方法论则是作为认知过程的宏观指导，它提供了一套全面的框架和步骤，帮助我们如何进行科学的思考和研究方法，方法论是提高认识水平、解决实际问题能力的重要工具。方法论涉及的不仅是科学研究方法，还包括思维方法、工作方法等。而思维模型则更多作为认知过程的具体参考，通过具体的模型帮助我们理解复杂现象或问题，并为决策提供理论支持。

通俗来说，方法论就像是开车时候的地图导航，帮助我们规划出最优路线；而思维模型则相当于在这条路线上，指导我们如何选择两点间的最短或最快路径。就像在开车时，如果面对磨磨唧唧的车流，我们就会根据各种实际因素来决定如何快速地超车。

就拿张雪峰老师作为具体的例子来说：张雪峰老师拥有非常丰富的中国教育考试知识和海量的实践经验。但如果你说，我要从 0 开始研究中国教育考试，最终达到张雪峰老师的水平也不是没有可能。可这个水平需要你大量的学习，实践，总结，再实践，迭代无数版本后才可能有机会达到。

正是因为张雪峰老师在中国教育考试方面的认知，大部分家长就会找到张雪峰老师，咨询如何规划孩子的大学志愿，毕竟家长在中国教育考试的认知不如张雪峰老师。可虽然张老师会针对具体问题提出了合理的建议，但大部分家长可能仍然揣着「旧」想法，半信半疑，并依旧会走弯路，那是为什么？

因为张雪峰老师的方法论和思维模型属于「黑盒理论」，我们无法透过表象深入理解本质，故此你可能就会持怀疑态度。毕竟实践才是检验真理的唯一标准。可高考只有一次，如果你检测成功了，皆大欢喜；检测失败了，那就自己承担。

> 不过题外话，我认为张雪峰老师还是属于拿钱办事的。例如有个高考状元 700+ 分的人。他也是不会给出太具体的建议，但不过大部分普通水平，反倒是会给出非常中肯的建议。

对于方法论及思维模型，我的一点心得：**无论是自上而下，还是自下而上的学习和实践，都是需要耗费不少的精力来内化的，请务必坚信「能量守恒定律」。** 而且我认为高效的路径是在某一专业领域深入研究，达到一定高度并且拥有一定造诣之后，在新的领域尝试从头再来，那么定会融会贯通！

最后回到《师从 ChatGPT》这个标题，之所以我选择这个标题是因为过去一年多，长时间与 ChatGPT 的交流深刻改变了我的认知和思考方式。

我认为 **AI 几乎是完美的，它永远不会受到思维定式的束缚。**并且只要你愿意教它，它可以迅速学习并适应新事物，而且 AI 认知的进化是不会受肉体的约束，毕竟我们随着年龄越来越大，很难再拥有青少年时期的学习精力。但是 AI 却不会，它可以通过不断地优化升级模型，并拥有几乎无限的学习精力。

我对于元认知的部分理解也是源于 ChatGPT，因为非常多具体的问题，如果你直接把问题丢给它，它回答得也并不出色。于是我开始各种尝试各种 Prompt，但是又发现 Prompt 虽各有不同，但还都是那几句套话。因此，我开始尝试构思更加深入的 Prompt。例如，在探讨特定问题时，我会先定义问题的范围，让 AI 先行解释其相关领域，再深入到该领域专家应具备什么样的知识，最终通过精心设计的对话，使 AI 能够在新的语境中发挥其最大的潜力。

目前主流的 AI 都是基于神经网络——一种受人脑启发的计算模型，其可以通过海量数据的喂养，调整神经单元突触的权重，进而从复杂的、高维的原始数据构成向低维度的投影，便于我们更容易去理解，有点类似于手指投影。不过，纵使目前 AI 再厉害，或者未来的 AGI 发布，我对于其是否可以拥有情感持怀疑态度。虽然我们的大脑与 AI 本质都是建模，可我们却拥有了无法解释来源的意识、情感、创造力。

可成也情感，败也情感。我们充斥着七情六欲，时常被情感控制。而 AI 却可以不被情感左右，针对问题可以不被干扰并尝试做出最优解。

自从去年 AI 的横空出世，让我们高估了其短期内的影响。不过到现在逐渐被普遍接受，从而又让我们低估其长远带来的变革。我坚定认为 **AI 不再仅仅是提升生产力的一个工具，更是内化知识、拓宽认知边界的「导师」。**

**我非常、非常建议，每个人都应该学会接纳变化，拥抱 AI，师从 ChatGPT！**

---

依旧是写了很久，也不多两周时间，写的我脑仁疼…… 🤯🤯🤯

《[富人的红灯与穷人的绿灯](https://blog.7wate.com/archives/fu-ren-de-hong-deng-yu-qiong-ren-de-lu-deng)》是这篇文章的药引子，说实话，当我通过「赛博莫比乌斯」，输入想表达的主题。AI 一行一行的输出内容，那「真的」就是莫比乌斯！

虽然也尝试了各种奇奇怪怪的姿势体验 ChatGPT 的功能，~~例如部署未审查版本 AI 尝试写色情小说等哈哈哈~~。但是这次元认知能力的提升，也让我也更深入理解：想要什么？AI 缺什么？怎么通过 AI 拿到想要的答案？

现在不要再单纯觉得 AI 呆瓜了，其实神经网络模型理论上可以模拟输出任意问题的结果，只是目前的 AI 在用我们可以理解的方式进行沟通。我不是宣扬 AI 可以创造一切，以及未来 AI 毁灭世界的信徒。只是通过 AI 更进一步的拓宽了认知的边界，拿到了我想要的答案。

至于未来如何，那就该吃吃该喝喝，明天去做桌哈哈（满月酒的家乡话）。

---

> 下图是创作过程中的文章草稿，也是本文的思维逻辑导图。基于 Obsidian 的原生插件——白板实现，原始文件可以在 github 主页 wiki 仓库下 Canvas 目录找到哈 ～

![思维逻辑导图](https://static.7wate.com/2024%2F04%2F19%2Fa60de947d4948ee53f0f507a76443ca2-%E5%B8%88%E4%BB%8E%20ChatGPT.png)
